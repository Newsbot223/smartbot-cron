import os
import json
import time
import hashlib
import requests
import feedparser
import re
from bs4 import BeautifulSoup
from datetime import datetime
from readability import Document

# --- ÐšÐ¾Ð½ÑÑ‚Ð°Ð½Ñ‚Ñ‹ ---
FEEDS = [
    "https://www.deutschlandfunk.de/nachrichten-100.rss",
    "https://www.deutschlandfunk.de/politikportal-100.rss",
    "https://www.deutschlandfunk.de/wirtschaft-106.rss",
    "https://www.spiegel.de/thema/deutschland/index.rss",
    "https://www.faz.net/rss/aktuell/politik/inland"
]

MAX_ARTICLES = 1000
MAX_TOKENS = 800
MAX_CHARS = 8000
MAX_AGE_SECONDS = 43200  # 12 Ñ‡Ð°ÑÐ¾Ð²

OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
CHAT_ID = os.getenv("CHAT_ID")
BOT_TOKEN = os.getenv("BOT_TOKEN")

HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "Content-Type": "application/json",
}

KEYWORDS = [
    "regierung", "bundestag", "wirtschaft", "ampel", "haushalt", "migration",
    "bÃ¼rgergeld", "afd", "spd", "cdu", "grÃ¼ne", "wahl", "streik",
    "arbeitsmarkt", "deutschland", "eu", "gesetz", "energie", "asyl", "krieg",
    "grenze", "grenzen", "grenzschutz", "bundespolizei", "flÃ¼chtlinge", "einreise"
]

BLOCKED_KEYWORDS = [
    "wetter", "wetterbericht", "regen", "sonnig", "heiter", "unwetter",
    "vorhersage", "temperature", "schnee", "hitze",
    "sport", "bundesliga", "fuÃŸball", "tor", "spiel", "trainer",
    "verein", "tabelle", "champions league", "olympia", "weltmeisterschaft",
    "spieltag", "tennis", "formel 1", "handball", "basketball"
]

# --- Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ñ‹ Ñ Ñ„Ð°Ð¹Ð»Ð°Ð¼Ð¸ ---
def generate_filename():
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    return f"sent_articles_{timestamp}.json"

def get_latest_filename_from_updates():
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/getUpdates"
    try:
        res = requests.get(url).json()
        files = []
        for update in res.get("result", []):
            msg = update.get("message", {})
            doc = msg.get("document")
            if doc and doc.get("file_name", "").startswith("sent_articles_"):
                files.append((doc["file_name"], doc["file_id"], msg.get("date", 0)))
        if not files:
            return None, None
        files.sort(key=lambda x: x[2], reverse=True)
        return files[0][0], files[0][1]
    except Exception as e:
        print("âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð¿Ð¾Ð¸ÑÐºÐµ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½ÐµÐ³Ð¾ Ñ„Ð°Ð¹Ð»Ð°:", e)
        return None, None

def download_latest_sent_json():
    filename, file_id = get_latest_filename_from_updates()
    if not file_id:
        print("ðŸ“­ ÐÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð¾Ð³Ð¾ Ñ„Ð°Ð¹Ð»Ð° Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸")
        return generate_filename()
    try:
        info = requests.get(f"https://api.telegram.org/bot{BOT_TOKEN}/getFile?file_id={file_id}").json()
        file_path = info["result"]["file_path"]
        url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{file_path}"
        data = requests.get(url).content
        with open(filename, "wb") as f:
            f.write(data)
        print(f"ðŸ“¥ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½ {filename} Ð¸Ð· Telegram")
        return filename
    except Exception as e:
        print("âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ Ñ„Ð°Ð¹Ð»Ð°:", e)
        return generate_filename()

def upload_sent_json(local_filename):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument"
    with open(local_filename, "rb") as f:
        files = {"document": f}
        data = {"chat_id": CHAT_ID, "caption": "âœ… ÐÐ¾Ð²Ñ‹Ð¹ sent_articles Ñ„Ð°Ð¹Ð»"}
        res = requests.post(url, files=files, data=data)
        print("ðŸ“¤ ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½:", local_filename, res.status_code)

def load_sent_articles():
    local_file = None
    for file in os.listdir():
        if file.startswith("sent_articles_") and file.endswith(".json"):
            local_file = file
            break

    if not local_file:
        print("ðŸ“‚ Ð›Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð» Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ...")
        local_file = download_latest_sent_json()

    try:
        with open(local_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except:
        data = {"urls": [], "hashes": [], "titles": []}

    return data, local_file

def save_sent_articles(data, local_file):
    data["urls"] = data["urls"][-MAX_ARTICLES:]
    data["hashes"] = data["hashes"][-MAX_ARTICLES:]
    data["titles"] = data.get("titles", [])[-MAX_ARTICLES:]

    with open(local_file, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    upload_sent_json(local_file)

# --- ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ ---
def summarize(text):
    prompt = f'''
Fasse diesen deutschen Nachrichtentext in 4â€“7 SÃ¤tzen zusammen. Verfasse zuerst einen spannenden, aber sachlichen Titel (ohne AnfÃ¼hrungszeichen), dann einen stilistisch ansprechenden Nachrichtentext. Nutze kurze AbsÃ¤tze und formuliere professionell und klar.

Text: {text}
'''
    try:
        res = requests.post("https://openrouter.ai/api/v1/chat/completions", headers=HEADERS, json={
            "model": "mistralai/mistral-7b-instruct",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7,
            "max_tokens": MAX_TOKENS
        }, timeout=60)
        res.raise_for_status()
        result = res.json()
        if "choices" in result and isinstance(result["choices"], list):
            return result["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print("Fehler bei Zusammenfassung:", e)
        return ""

def send_message(text):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    payload = {
        "chat_id": CHAT_ID,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": False
    }
    return requests.post(url, json=payload).status_code == 200

def get_article_text(url):
    try:
        response = requests.get(url, timeout=10)
        html = response.text
        doc = Document(html)
        summary = doc.summary()
        text = BeautifulSoup(summary, "html.parser").get_text(separator="\n", strip=True)
        return text
    except Exception as e:
        print("âš  ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐµ ÑÑ‚Ð°Ñ‚ÑŒÐ¸:", e)
        return ""

# --- main ---
def main():
    sent, local_file = load_sent_articles()

    for feed_url in FEEDS:
        feed = feedparser.parse(feed_url)
        for entry in feed.entries:
            url = entry.link
            title = entry.title

            if url in sent["urls"] or title in sent["titles"]:
                print(f"â© Bereits verarbeitet: {title}")
                continue

            published = entry.get("published_parsed")
            if published:
                pub_date = datetime.fromtimestamp(time.mktime(published))
                if (datetime.utcnow() - pub_date).total_seconds() > MAX_AGE_SECONDS:
                    print(f"â³ Zu alt, Ã¼bersprungen: {title}")
                    continue

            full_text = get_article_text(url)

            if len(full_text) > MAX_CHARS:
                print(f"âš  Zu lang, Ã¼bersprungen: {title} ({len(full_text)} Zeichen)")
                continue

            if len(full_text) < 200:
                print(f"âš  Ãœbersprungen ({feed_url}): {title} (zu kurz)")
                continue

            if not any(keyword.lower() in full_text.lower() for keyword in KEYWORDS):
                print(f"â›” Thema nicht relevant: {title}")
                continue

            if any(word in full_text.lower() for word in BLOCKED_KEYWORDS):
                print(f"âŒ Thema blockiert: {title}")
                continue

            hash_base = (title + full_text[:300].lower()).strip()
            hash_ = hashlib.md5(hash_base.encode("utf-8")).hexdigest()
            if hash_ in sent["hashes"]:
                continue

            print(f"ðŸ”„ Analysiere: {title}")
            summary = summarize(full_text)
            if not summary:
                continue

            caption = f"<b>ðŸ“° {title}</b>\n\n{summary}\n\nðŸ”— <a href='{url}'>Weiterlesen</a>"

            success = send_message(caption)
            if success:
                print("âœ… Gesendet")
                sent["urls"].append(url)
                sent["hashes"].append(hash_)
                if title not in sent["titles"]:
                    sent["titles"].append(title)
            else:
                print("âš  Fehler beim Senden")

    save_sent_articles(sent, local_file)

if __name__ == "__main__":
    main()
